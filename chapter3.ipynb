{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPCzkKZTIx3/Ydy/SboKF9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/space4VV/LLM_trailblazr/blob/main/chapter3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyfOqckmWup9",
        "outputId": "44e035b6-5248-4369-d117-6d37c8473a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.1+cu121\n"
          ]
        }
      ],
      "source": [
        "#print torch version\n",
        "import torch\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "inputs = torch.tensor(\n",
        "   [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLU_e8s9X5t8",
        "outputId": "e2ea7767-898b-4560-80b0-011348ecfa6e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4300, 0.1500, 0.8900],\n",
            "        [0.5500, 0.8700, 0.6600],\n",
            "        [0.5700, 0.8500, 0.6400],\n",
            "        [0.2200, 0.5800, 0.3300],\n",
            "        [0.7700, 0.2500, 0.1000],\n",
            "        [0.0500, 0.8000, 0.5500]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We use input sequence element 2, as an example to compute context vector z\n",
        "- The context vector is \"context\"-specific to a certain input\n"
      ],
      "metadata": {
        "id": "LwRyGdElZcM5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vUrWNpwvF7lK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute the attention weights and context vector for input 2\n",
        "\n"
      ],
      "metadata": {
        "id": "Ag4BtWZZJuu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - compute the unnormalized attention scores by computing the dot product between the query and all other input tokens:\n"
      ],
      "metadata": {
        "id": "_YXV3S79F8f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1]\n",
        "print(query)\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "for i, x_i in enumerate(inputs):\n",
        "    attn_scores_2[i] = torch.dot(x_i,query)\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnQsY4D8Y-m8",
        "outputId": "12425dbf-7f27-496d-afc8-8bccd1c70d89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5500, 0.8700, 0.6600])\n",
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Normalize the attention scores so that they sum upto 1\n"
      ],
      "metadata": {
        "id": "yUeOusvJGINn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2_tmp = attn_scores_2 /attn_scores_2.sum()\n",
        "print(attn_weights_2_tmp)\n",
        "print(\"sum of attn scores:\",attn_weights_2_tmp.sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "dRizBLuiaG_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174237f2-0d36-4046-d50a-00e872762e45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
            "sum of attn scores: tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, in practice, using the softmax function for normalization, which is better at handling extreme values and has more desirable gradient properties during training, is common and recommended."
      ],
      "metadata": {
        "id": "lDGTzL64Elry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# naive softmax\n",
        "def softmax_naive(x):\n",
        "  return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
        "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
        "print(attn_weights_2_naive)\n",
        "print(\"sum of attn scores:\",attn_weights_2_naive.sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZdzrHoHEIpT",
        "outputId": "d1420d1f-2765-4dc2-e717-ad1b70ea4ce5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "sum of attn scores: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in practice its better to use the one from torch directly\n",
        "atten_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
        "print(atten_weights_2)\n",
        "print(\"sum of attn scores:\",atten_weights_2.sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne4ZY7GCE_Qu",
        "outputId": "df8359f1-1bee-4921-feaf-515a8b9de3ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "sum of attn scores: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - compute the context vector by multiplying the embedded input tokens, with the attention weights and sum the resulting vectors"
      ],
      "metadata": {
        "id": "HnZFPE6DGMtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"inputs:\",inputs)\n",
        "print(\"attention_weights\",atten_weights_2)\n",
        "query =  inputs[1] # 2nd token is the query\n",
        "context_vec_2  = torch.zeros(query.shape)\n",
        "for i, x_i in enumerate(inputs):\n",
        "    context_vec_2 += atten_weights_2[i] * x_i\n",
        "print(\"context_vector -\",context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0XGukxEF2Cx",
        "outputId": "a7681a04-d7ae-4e7d-99fc-a1efaa5d6bdf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: tensor([[0.4300, 0.1500, 0.8900],\n",
            "        [0.5500, 0.8700, 0.6600],\n",
            "        [0.5700, 0.8500, 0.6400],\n",
            "        [0.2200, 0.5800, 0.3300],\n",
            "        [0.7700, 0.2500, 0.1000],\n",
            "        [0.0500, 0.8000, 0.5500]])\n",
            "attention_weights tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "context_vector - tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute all attention weights and context vectors"
      ],
      "metadata": {
        "id": "wfBgF-hUJ1t1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = torch.empty((inputs.shape[0], inputs.shape[0]))\n",
        "for i, x_i in enumerate(inputs):\n",
        "    for j, x_j in enumerate(inputs):\n",
        "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3ub7M7tHIk_",
        "outputId": "1e5fe31d-12a3-4bad-b336-0d71ec108421"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matric multiplication vs the above for loops to improve the performance\n",
        "attn_scores = inputs @ inputs.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbJyuP-aNEDK",
        "outputId": "fb63c196-07ab-416a-aead-d7f095029a0d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now normalize\n",
        "attn_weights = torch.softmax(attn_scores, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojBTVAI5NqNp",
        "outputId": "eb3f3301-ad40-485c-92e8-b8eeb9034310"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now calculate context vectors\n",
        "all_context_vectors = attn_weights @ inputs\n",
        "print(all_context_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6avb3xhNxXq",
        "outputId": "8ef9b82a-4879-457a-a0bf-56bd7a284c7d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing self-attention with trainable weights\n",
        "There are only slight differences compared to the basic attention mechanism introduced earlier:\n",
        "- The most notable difference is the introduction of weight matrices that are updated during model training\n",
        "- These trainable weight matrices are crucial so that the model (specifically, the attention module inside the model) can learn to produce \"good\" context vectors\n"
      ],
      "metadata": {
        "id": "ei-dkcLjPZc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we need 3 weight matrices K,Q,V -  these 3 matrices project the embedded input\n",
        "# tokens into K;Q;V Vectors"
      ],
      "metadata": {
        "id": "oxOf_j1FOHqA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j64axt5dUP6r",
        "outputId": "f9a1a317-fc4f-4e07-8fe8-9cf226427da7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4300, 0.1500, 0.8900],\n",
            "        [0.5500, 0.8700, 0.6600],\n",
            "        [0.5700, 0.8500, 0.6400],\n",
            "        [0.2200, 0.5800, 0.3300],\n",
            "        [0.7700, 0.2500, 0.1000],\n",
            "        [0.0500, 0.8000, 0.5500]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = inputs[1]\n",
        "print(x_2.shape)\n",
        "d_in = inputs.shape[1]\n",
        "print(\"input dim:\",d_in)\n",
        "d_out = 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xLg2_WESUeQ",
        "outputId": "b896dfdf-23c4-4b37-edfa-701783c5ef0f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3])\n",
            "input dim: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the 3 weight matrices\n",
        "torch.manual_seed(123)\n",
        "w_query = torch.nn.Parameter(torch.randn(d_in, d_out),requires_grad=False)\n",
        "w_key = torch.nn.Parameter(torch.randn(d_in, d_out),requires_grad=False)\n",
        "w_value = torch.nn.Parameter(torch.randn(d_in, d_out),requires_grad=False)"
      ],
      "metadata": {
        "id": "W1UuqMMcSiPK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = x_2 @ w_query # _2 because it's with respect to the 2nd input element\n",
        "key_2 = x_2 @ w_key\n",
        "value_2 = x_2 @ w_value\n",
        "print(\"query:\",query_2)\n",
        "print(\"key:\",key_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3q9Q4QZTti-",
        "outputId": "8b6a15f3-7746-41cb-f0a6-1e0d5dedcc2e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query: tensor([-1.1729, -0.0048])\n",
            "key: tensor([-0.1142, -0.7676])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ w_key\n",
        "values = inputs @ w_value\n",
        "print(\"shape of keys:\",keys.shape)\n",
        "print(\"shape of values:\",values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8ulKiEFTzNh",
        "outputId": "d74f5df0-1384-4bbf-a97e-1b27cadb2973"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of keys: torch.Size([6, 2])\n",
            "shape of values: torch.Size([6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 2, we compute the unnormalized attention scores by computing the dot\n",
        "#product between the query and each key vector:\n",
        "\n",
        "keys_2 = keys[1]\n",
        "print(\"keys2:\",keys_2)\n",
        "print(\"query2:\",query_2)\n",
        "attn_score_22 = torch.dot(query_2, keys_2)\n",
        "print(\"attention score:\",attn_score_22)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kNL1yVPUrKe",
        "outputId": "8368562b-16f9-43ed-926b-0434194b8880"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys2: tensor([-0.1142, -0.7676])\n",
            "query2: tensor([-1.1729, -0.0048])\n",
            "attention score: tensor(0.1376)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_2 = query_2 @ keys.T\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjd2VAuyV7Bf",
        "outputId": "2d4ae80d-3351-465d-e921-e79735b1097e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.2172,  0.1376,  0.1730, -0.0491,  0.7616, -0.3809])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute attention weights\n",
        "d_k = keys.shape[1]\n",
        "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
        "print(attn_weights_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_R-KHOUWDwy",
        "outputId": "93109daf-ceb1-4e03-d884-7b57c4307b4d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1704, 0.1611, 0.1652, 0.1412, 0.2505, 0.1117])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 4, we now compute the context vector for input query vector 2:\n",
        "\n",
        "context_vec_2 = attn_weights_2 @ values\n",
        "print(context_vec_2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apcvn6zsYUrO",
        "outputId": "ed7da2a5-3cd8-408d-9405-7ced0d24d24b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2854, 0.4081])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self attention class\n"
      ],
      "metadata": {
        "id": "P-_LMZ0EasEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class SelfAttention_V1(nn.Module):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    self.w_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.w_key = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.w_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = x @ self.w_key\n",
        "    values = x @ self.w_value\n",
        "    queries = x @ self.w_query\n",
        "    attn_scores = queries @ keys.T # omega\n",
        "    attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "        )\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec\n",
        "\n",
        "torch.manual_seed(123)\n",
        "self_attn_v1 = SelfAttention_V1(d_in, d_out)\n",
        "print(self_attn_v1(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkF9PQexanMc",
        "outputId": "2b9271a7-6399-4c3c-bf1e-333c53184577"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2996, 0.8053],\n",
            "        [0.3061, 0.8210],\n",
            "        [0.3058, 0.8203],\n",
            "        [0.2948, 0.7939],\n",
            "        [0.2927, 0.7891],\n",
            "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new class using pytorch linear layer\n",
        "class SelfAttention_V2(nn.Module):\n",
        "  def __init__(self, d_in, d_out,qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.w_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.w_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.w_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = self.w_key(x)\n",
        "    values = self.w_query(x)\n",
        "    queries = self.w_value(x)\n",
        "    attn_scores = queries @ keys.T # omega\n",
        "    attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "        )\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec\n",
        "\n",
        "torch.manual_seed(789)\n",
        "self_attn_v2 = SelfAttention_V2(d_in, d_out)\n",
        "print(self_attn_v2(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw-NQgvEbhLY",
        "outputId": "b461e673-fdf7-453d-822e-a9985685ec3c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6733, -0.3186],\n",
            "        [ 0.6726, -0.3185],\n",
            "        [ 0.6722, -0.3183],\n",
            "        [ 0.6739, -0.3189],\n",
            "        [ 0.6656, -0.3147],\n",
            "        [ 0.6774, -0.3207]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hiding future words with causal attention\n",
        "In causal attention, the attention weights above the diagonal are masked, ensuring that for any given input, the LLM is unable to utilize future tokens while calculating the context vectors with the attention weight\n"
      ],
      "metadata": {
        "id": "nf8qtCGfiAsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Causal self-attention ensures that the model's prediction for a certain position\n",
        "#  in a sequence is only dependent on the known outputs at previous positions, not on future positions"
      ],
      "metadata": {
        "id": "3k6oU7sfcXV9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = self_attn_v2.w_query(inputs)\n",
        "keys = self_attn_v2.w_key(inputs)\n",
        "attn_scores = queries @ keys.T\n",
        "print(attn_scores)\n",
        "\n",
        "attn_weights = torch.softmax(attn_scores/keys.shape[-1]**0.5,dim=-1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ2EuEGXmH2U",
        "outputId": "7784281d-b752-4388-d6a4-c2ce3cccfb22"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2899,  0.0716,  0.0760, -0.0138,  0.1344, -0.0511],\n",
            "        [ 0.4656,  0.1723,  0.1751,  0.0259,  0.1771,  0.0085],\n",
            "        [ 0.4594,  0.1703,  0.1731,  0.0259,  0.1745,  0.0090],\n",
            "        [ 0.2642,  0.1024,  0.1036,  0.0186,  0.0973,  0.0122],\n",
            "        [ 0.2183,  0.0874,  0.0882,  0.0177,  0.0786,  0.0144],\n",
            "        [ 0.3408,  0.1270,  0.1290,  0.0198,  0.1290,  0.0078]],\n",
            "       grad_fn=<MmBackward0>)\n",
            "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
            "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
            "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
            "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
            "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# masking\n",
        "context_length = attn_scores.shape[0]\n",
        "print(context_length)\n",
        "# set elements below the main diagonal (including the diagonal itself) set to 1 and above the main diagonal set to 0:\n",
        "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYiuL8mHmp13",
        "outputId": "fc92a56b-0593-486e-b27b-6afdbaab38f2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_simple = attn_weights * mask_simple\n",
        "print(masked_simple)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG4CGVCjpJkT",
        "outputId": "b1baaf14-ff11-4cf0-ce07-16c1e9ca4b71"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
            "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we should re normalize after masking to ensure rows sums up to 1\n",
        "row_sums = masked_simple.sum(dim=1, keepdim=True)\n",
        "print(\"row_sums: \\n\",row_sums)\n",
        "masked_simple_norm = masked_simple / row_sums\n",
        "print(\"masked_simple_norm: \\n\",masked_simple_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDywSHPOpWyH",
        "outputId": "017618f1-b61e-4961-b892-d7fb9d45b377"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "row_sums: \n",
            " tensor([[0.1921],\n",
            "        [0.3700],\n",
            "        [0.5357],\n",
            "        [0.6775],\n",
            "        [0.8415],\n",
            "        [1.0000]], grad_fn=<SumBackward1>)\n",
            "masked_simple_norm: \n",
            " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
            "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
            "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instead of zeroing out attention weights above the diagonal and renormalizing the results,\n",
        "#we can mask the unnormalized attention scores above the diagonal with negative infinity before they enter the softmax function:\n",
        "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "masked = attn_scores*masked_fill(mask.bool(),-torch.inf)\n",
        "print(masked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "O0Y8HoB-qawm",
        "outputId": "d086449f-1542-45d6-fb48-59ceb3e07a0f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'masked_fill' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-d3a3cac5d2cd>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#we can mask the unnormalized attention scores above the diagonal with negative infinity before they enter the softmax function:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmasked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_scores\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'masked_fill' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding dropouts after computing attn weights to reduce overfitting\n",
        "torch.manual_seed(123)\n",
        "dropout = torch.nn.Dropout(0.5) #50%\n",
        "example = torch.ones(6,6)\n",
        "print(dropout(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kJ6TUhKqu4V",
        "outputId": "8fe12eeb-325a-4ae6-c28b-2e744b8b5787"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 2., 2., 2., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.],\n",
            "        [0., 0., 2., 0., 2., 0.],\n",
            "        [2., 2., 0., 0., 0., 2.],\n",
            "        [2., 0., 0., 0., 0., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "print(dropout(attn_weights))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YQeszVasw3I",
        "outputId": "6608e9f8-a804-4f6d-e764-9c7f2f10caec"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3843, 0.3293, 0.3303, 0.3100, 0.3442, 0.3019],\n",
            "        [0.0000, 0.3318, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.3325, 0.0000, 0.3328, 0.0000],\n",
            "        [0.3738, 0.3334, 0.0000, 0.0000, 0.0000, 0.3128],\n",
            "        [0.3661, 0.0000, 0.0000, 0.0000, 0.0000, 0.3169],\n",
            "        [0.0000, 0.3327, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting all to a compact class\n",
        "One more thing is to implement the code to handle batches consisting of more than one input so that our CausalAttention\n",
        "class supports the batch outputs produced by the data loader we implemented in chapter 2\n",
        "- For simplicity, to simulate such batch input, we duplicate the input text example: -->"
      ],
      "metadata": {
        "id": "kTQqdJ43uG0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack([inputs,inputs],dim=0)\n",
        "print(batch)\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaYGhMWsszv2",
        "outputId": "8e581cdb-45d6-4748-9069-5c6177522b23"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.4300, 0.1500, 0.8900],\n",
            "         [0.5500, 0.8700, 0.6600],\n",
            "         [0.5700, 0.8500, 0.6400],\n",
            "         [0.2200, 0.5800, 0.3300],\n",
            "         [0.7700, 0.2500, 0.1000],\n",
            "         [0.0500, 0.8000, 0.5500]],\n",
            "\n",
            "        [[0.4300, 0.1500, 0.8900],\n",
            "         [0.5500, 0.8700, 0.6600],\n",
            "         [0.5700, 0.8500, 0.6400],\n",
            "         [0.2200, 0.5800, 0.3300],\n",
            "         [0.7700, 0.2500, 0.1000],\n",
            "         [0.0500, 0.8000, 0.5500]]])\n",
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length,dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out=d_out\n",
        "    self.w_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.w_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.w_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape # New batch dimension b\n",
        "    keys = self.w_key(x)\n",
        "    queries = self.w_query(x)\n",
        "    values = self.w_value(x)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n",
        "    attn_scores.masked_fill_(  # New, _ ops are in-place\n",
        "        self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # :num_tokens to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "    )\n",
        "    attn_weights = self.dropout(attn_weights) # New\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "context_length = batch.shape[1]\n",
        "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
        "\n",
        "context_vecs = ca(batch)\n",
        "\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXxITOptuXoS",
        "outputId": "2b7311db-fd9e-494b-d574-39404b7b54a6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.4519,  0.2216],\n",
            "         [-0.5874,  0.0058],\n",
            "         [-0.6300, -0.0632],\n",
            "         [-0.5675, -0.0843],\n",
            "         [-0.5526, -0.0981],\n",
            "         [-0.5299, -0.1081]],\n",
            "\n",
            "        [[-0.4519,  0.2216],\n",
            "         [-0.5874,  0.0058],\n",
            "         [-0.6300, -0.0632],\n",
            "         [-0.5675, -0.0843],\n",
            "         [-0.5526, -0.0981],\n",
            "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multihead attention\n",
        "The main idea behind multi-head attention is to run the attention mechanism multiple times (in parallel) with different, learned linear projections. This allows the model to jointly attend to information from different representation subspaces at different positions."
      ],
      "metadata": {
        "id": "1oSFaOyHzWW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "  def __init__(self, d_in, d_out, num_heads, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList(\n",
        "        [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) for _ in range(num_heads)]\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "context_lenghth = batch.shape[1] # no of tokens\n",
        "mha = MultiHeadAttentionWrapper(d_in, d_out,2, context_length, 0.0,)\n",
        "context_vecs = mha(batch)\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)\n",
        "# In the implementation above, the embedding dimension is 4, because we d_out=2 as\n",
        "# the embedding dimension for the key, query, and value vectors as well as the\n",
        "# context vector. And since we have 2 attention heads, we have the output embedding dimension 2*2=4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHEI0zTkyez7",
        "outputId": "6b485786-67c8-4e3f-be92-2eca15746ba1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
            "\n",
            "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standalone multiattention\n"
      ],
      "metadata": {
        "id": "67Ub6z2h0hZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "batch_size, context_length, d_in = batch.shape\n",
        "d_out = 2\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "\n",
        "context_vecs = mha(batch)\n",
        "\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORrekloi0N7C",
        "outputId": "d67d5407-14c2-477f-9b53-cf962a75d0c7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.3190, 0.4858],\n",
            "         [0.2943, 0.3897],\n",
            "         [0.2856, 0.3593],\n",
            "         [0.2693, 0.3873],\n",
            "         [0.2639, 0.3928],\n",
            "         [0.2575, 0.4028]],\n",
            "\n",
            "        [[0.3190, 0.4858],\n",
            "         [0.2943, 0.3897],\n",
            "         [0.2856, 0.3593],\n",
            "         [0.2693, 0.3873],\n",
            "         [0.2639, 0.3928],\n",
            "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbiIIVO50lPO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}